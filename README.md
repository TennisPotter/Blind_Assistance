ğŸ“±ğŸ§­ Blind Assistance Application
Empowering the visually impaired with AI-powered Object Detection, Voice Navigation, and Real-Time Voice Control.

ğŸ“Œ Overview
This is a complete Blind Assistance System that helps visually impaired users with

Object Detection in real-time using the mobile camera.

Voice-enabled Navigation using Google Maps.

Full voice interaction for hands-free access.

Built as part of an MCA Final Year Project using Android Studio (Java/Kotlin Application.

ğŸš€ Features

Real-Time Object Detection using ML Kit

Google Maps Navigation with Voice Input

Text-to-Speech for every detected object

Voice Commands for Navigation and Control

Gesture support (Swipe to navigate)

Camera toggle (Front/Back)

Splash Screen with Branding

ğŸ§° Tech Stack

Java / Kotlin

ML Kit (Object Detection)

Google Maps API

Text-to-Speech (TTS)

Speech Recognition

XML (UI Design)

ğŸ”¨ Steps

1. Clone the repo
2. Open in Android Studio
3. Add your google-services.json
4. Build and Run on Device

pip install -r requirements.txt

ğŸ™ï¸ Voice Commands
Command	Action
"Detect objects"	Starts camera & detects objects
"Start navigation"	Opens NavigationActivity
"Go to main menu"	Returns to home screen
"Switch camera"	Front/Back toggle
"Exit app"	Closes application

âš™ï¸ How It Works
Object Detection is powered by ML Kit (mobile) and MobileNet SSD (web).

Voice input is recognized using Androidâ€™s SpeechRecognizer and Web Speech API.

Navigation is integrated with Google Maps and reads directions aloud.

The entire interface is optimized for non-visual interaction using voice and gestures.

ğŸ‘¥ Contributors
Name : Tennis

Purpose : College Final Year Projects

â­ GitHub
If this project helped you or inspired you

Any Queries 
   gmail: tennispotter123@gmail.com
