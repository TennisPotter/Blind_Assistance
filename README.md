📱🧭 Blind Assistance Application
Empowering the visually impaired with AI-powered Object Detection, Voice Navigation, and Real-Time Voice Control.

📌 Overview
This is a complete Blind Assistance System that helps visually impaired users with

Object Detection in real-time using the mobile camera.

Voice-enabled Navigation using Google Maps.

Full voice interaction for hands-free access.

Built as part of an MCA Final Year Project using Android Studio (Java/Kotlin Application.

🚀 Features

Real-Time Object Detection using ML Kit

Google Maps Navigation with Voice Input

Text-to-Speech for every detected object

Voice Commands for Navigation and Control

Gesture support (Swipe to navigate)

Camera toggle (Front/Back)

Splash Screen with Branding

🧰 Tech Stack

Java / Kotlin

ML Kit (Object Detection)

Google Maps API

Text-to-Speech (TTS)

Speech Recognition

XML (UI Design)

🔨 Steps

1. Clone the repo
2. Open in Android Studio
3. Add your google-services.json
4. Build and Run on Device

pip install -r requirements.txt

🎙️ Voice Commands
Command	Action
"Detect objects"	Starts camera & detects objects
"Start navigation"	Opens NavigationActivity
"Go to main menu"	Returns to home screen
"Switch camera"	Front/Back toggle
"Exit app"	Closes application

⚙️ How It Works
Object Detection is powered by ML Kit (mobile) and MobileNet SSD (web).

Voice input is recognized using Android’s SpeechRecognizer and Web Speech API.

Navigation is integrated with Google Maps and reads directions aloud.

The entire interface is optimized for non-visual interaction using voice and gestures.

👥 Contributors
Name : Tennis

Purpose : College Final Year Projects

⭐ GitHub
If this project helped you or inspired you

Any Queries 
   gmail: tennispotter123@gmail.com
